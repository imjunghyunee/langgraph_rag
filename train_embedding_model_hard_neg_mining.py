# -------------------------------------------------------------------
# train_embedding_model.py
#  - Positive-aware Hard-Negative Mining(NV-Retriever) + Triplet Loss
#  - í•™ìŠµ ë°ì´í„°: [{"query": "...", "passage": "..."}] or [[query, passage], ...]
#  - ì¶œë ¥: íŒŒì¸íŠœë‹ëœ SentenceTransformer ëª¨ë¸
# -------------------------------------------------------------------

from __future__ import annotations

import json, logging, argparse
from pathlib import Path
from typing import List, Tuple

import torch
import numpy as np
from tqdm import tqdm
from sentence_transformers import (
    SentenceTransformer,
    InputExample,
    losses,
    util,
)
from torch.utils.data import DataLoader

# --------------------- í•˜ì´í¼ íŒŒë¼ë¯¸í„° ê¸°ë³¸ê°’ ----------------------
STUDENT_MODEL_NAME = "jinaai/jina-embeddings-v3"
TEACHER_MODEL_NAME = "intfloat/e5-mistral-7b-instruct"
BATCH_SIZE = 16  # Triplet ì˜ˆì œ í•˜ë‚˜ë‹¹ 3ê°œì˜ ë¬¸ì¥ì„ í¬í•¨í•˜ë¯€ë¡œ 16ì´ ì•ˆì „
EPOCHS = 3
LR = 2e-5
TOP_K = 20  # mining ì‹œ í›„ë³´ ê°œìˆ˜
PERC_THRESHOLD = 0.95  # pos_score * 0.95 ë³´ë‹¤ ë†’ì€ neg ì œì™¸
WARMUP_RATIO = 0.1  # ì´ ìŠ¤í…ì˜ 10 %

# ------------------------- ë¡œê¹… ì„¤ì • -------------------------------
logging.basicConfig(
    format="%(asctime)s | %(levelname)s | %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
    level=logging.INFO,
)


# ------------------- Hard-Negative Mining í•¨ìˆ˜ ---------------------
def mine_hard_negatives(
    teacher: SentenceTransformer,
    queries: List[str],
    positives: List[str],
    top_k: int = TOP_K,
    perc_threshold: float = PERC_THRESHOLD,
    batch_size: int = 256,
    device: str = "cpu",
) -> List[Tuple[str, str, str]]:
    """
    Positive-aware TopK-PercPos ë°©ì‹ìœ¼ë¡œ (query, positive, hard_negative) triplet ë¦¬ìŠ¤íŠ¸ ë°˜í™˜
    """
    logging.info("ğŸª¨ Hard-negative mining ì‹œì‘ â€¦")
    teacher.to(device)
    teacher.eval()

    # 1) ì „ì²´ positive ë¬¸ë‹¨ ì„ë² ë”© í•œ ë²ˆì— ê³„ì‚°
    all_pass_emb = teacher.encode(
        positives,
        batch_size=batch_size,
        show_progress_bar=True,
        convert_to_tensor=True,
        normalize_embeddings=True,
    )  # shape=(N, D)

    triplets: List[Tuple[str, str, str]] = []

    # 2) ê° ì¿¼ë¦¬ë§ˆë‹¤ hardest negative 1ê°œ ì„ íƒ
    for q, pos in tqdm(
        list(zip(queries, positives)), desc="mining", total=len(queries)
    ):
        q_emb = teacher.encode(q, convert_to_tensor=True, normalize_embeddings=True)
        # cosine scores = dot product (ì •ê·œí™”ëœ ìƒíƒœ)
        scores = (all_pass_emb @ q_emb).cpu().numpy()  # (N,)

        pos_emb = teacher.encode(pos, convert_to_tensor=True, normalize_embeddings=True)
        pos_score = float(util.cos_sim(q_emb, pos_emb)[0])

        # top-k í›„ë³´ ì¸ë±ìŠ¤ (ìê¸° ìì‹  í¬í•¨ ê°€ëŠ¥)
        top_idx = scores.argsort()[::-1][: top_k + 1]

        neg_idx = None
        for idx in top_idx:
            cand, score = positives[idx], scores[idx]
            if cand == pos:  # positive ìì²´ëŠ” ì œì™¸
                continue
            # pos_score * Î± ë³´ë‹¤ ë†’ì€ candidate ëŠ” ì œì™¸ (false-negative ê°€ëŠ¥)
            if score < pos_score * perc_threshold:
                neg_idx = idx
                break

        # ì˜ˆì™¸: ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” negê°€ ì—†ìœ¼ë©´ ìµœì € ì ìˆ˜ passage ì‚¬ìš©
        if neg_idx is None:
            neg_idx = scores.argmin()

        triplets.append((q, pos, positives[neg_idx]))

    logging.info(f"âœ… Hard-negatives mined: {len(triplets)}")
    return triplets


# --------------------- ë°ì´í„° ë¡œë“œ & ì „ì²˜ë¦¬ ------------------------
def load_pairs(data_path: Path) -> List[Tuple[str, str]]:
    """
    ë‹¤ì–‘í•œ JSON í˜•íƒœ([q, p] or {"query": q, "passage": p}) ì§€ì›
    """
    logging.info(f"ë°ì´í„° ë¡œë“œ: {data_path}")
    with data_path.open("r", encoding="utf-8") as f:
        raw = json.load(f)

    pairs: List[Tuple[str, str]] = []
    for item in raw:
        if isinstance(item, list):  # [query, passage]
            query, passage = item
        elif isinstance(item, dict):  # {"query": ..., "passage": ...}
            query = item["query"]
            passage = item["passage"]
        else:
            raise ValueError("ì§€ì›í•˜ì§€ ì•ŠëŠ” ë°ì´í„° í¬ë§·")
        pairs.append((query.strip(), passage.strip()))
    logging.info(f"ì´ ìŒ ê°œìˆ˜: {len(pairs)}")
    return pairs


def build_dataloader(
    triplets: List[Tuple[str, str, str]],
    batch_size: int = BATCH_SIZE,
) -> DataLoader:
    """
    (q, pos, neg) â†’ InputExample(texts=[q, pos, neg])
    """
    examples = [InputExample(texts=list(tpl)) for tpl in triplets]
    return DataLoader(examples, shuffle=True, batch_size=batch_size)


# -------------------------- í•™ìŠµ ë£¨í‹´ -----------------------------
def train(
    student: SentenceTransformer,
    dataloader: DataLoader,
    epochs: int,
    lr: float,
    warmup_ratio: float,
    output_dir: Path,
):
    """
    TripletLoss ë¡œ íŒŒì¸íŠœë‹
    """
    total_steps = len(dataloader) * epochs
    warmup_steps = int(total_steps * warmup_ratio)

    logging.info(
        f"í•™ìŠµ ì‹œì‘  | epochs={epochs}  total_steps={total_steps}  warmup={warmup_steps}"
    )

    loss_fn = losses.TripletLoss(
        student,
        distance_metric=losses.TripletDistanceMetric.COSINE,
        margin=0.05,
    )

    student.fit(
        train_objectives=[(dataloader, loss_fn)],
        epochs=epochs,
        warmup_steps=warmup_steps,
        optimizer_params={"lr": lr},
        output_path=str(output_dir),
        show_progress_bar=True,
    )
    logging.info(f"ëª¨ë¸ ì €ì¥ ì™„ë£Œ â†’ {output_dir}")


# ------------------------------ main -----------------------------
def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--data", type=Path, required=True, help="ìŒ ë°ì´í„° JSON ê²½ë¡œ")
    parser.add_argument("--output", type=Path, required=True, help="ëª¨ë¸ ì €ì¥ í´ë”")
    parser.add_argument("--student", default=STUDENT_MODEL_NAME)
    parser.add_argument("--teacher", default=TEACHER_MODEL_NAME)
    args = parser.parse_args()

    # 1) ëª¨ë¸ ë¡œë“œ
    device = "cuda" if torch.cuda.is_available() else "cpu"
    logging.info(f"Device: {device}")

    logging.info(f"ğŸ“š Student ëª¨ë¸ ë¡œë“œ: {args.student}")
    student = SentenceTransformer(args.student, trust_remote_code=True).to(device)

    logging.info(f"ğŸ“ Teacher ëª¨ë¸ ë¡œë“œ: {args.teacher}")
    teacher = SentenceTransformer(args.teacher).to(device)

    # 2) ë°ì´í„° ë¡œë“œ
    pairs = load_pairs(args.data)
    queries, positives = zip(*pairs)

    # 3) Hard-negative mining
    triplets = mine_hard_negatives(
        teacher,
        list(queries),
        list(positives),
        top_k=TOP_K,
        perc_threshold=PERC_THRESHOLD,
        device=device,
    )

    # 4) DataLoader
    dataloader = build_dataloader(triplets, batch_size=BATCH_SIZE)

    # 5) í•™ìŠµ
    args.output.mkdir(parents=True, exist_ok=True)
    train(
        student=student,
        dataloader=dataloader,
        epochs=EPOCHS,
        lr=LR,
        warmup_ratio=WARMUP_RATIO,
        output_dir=args.output,
    )


if __name__ == "__main__":
    main()
